# Final

## Brief
For the final your are free to choose what you'd like to do. The project should be a creative use of machine learning. It should be more ambitious in scope compared to what we've done so far this semester. You could do any number of things. A few sample ideas are:
* Build upon and fully complete one of your projects from earlier in the semester
* Create an interactive classification app or game [(example)](https://experiments.withgoogle.com/ai/emoji-scavenger)
* Create a physical comic book using style transfer
* Create an interactive dance performance
* Generate a musical composition or an EP of songs
* Create a music/sound generation tool
* Create a twitter bot (a variation could be a bot that learns and grows from people's responses)
* Print out a series of AI enabled art
* Create an interactive application (tool/game/art piece) of char-rnn like text generation 
* Create an art piece that illustrates/amplifies characteristics of this technology (could be illuminating or comedic or both)
* Train an LSTM on SVG data and output new SVGs

The list could go on and on. The above should be considered far from exhaustive.

You may work within a group or by yourself. 

## Grading Rubric
* 25% Creative Thinking: The project should not be just reproducing things using the tools we've looked at. It should have some novel implementation or approach in the application of the tech. Depending on the project, this could include indication of development of personal style/taste (if art project for example), and/or imaginative implementations of the tech in exploring ideas. 
* 25% Production Quality: The project needs to be well polished, with considerable work put into the finished work.
* 25% Clear Conceptual Underpinning: The project needs to be well thought out, and have a clear concept that you are working with from start to finish.
* 18% Machine Learning Application: The project should use and benefit from machine learning.
* 7% Press: The project execution and documentation should be at a level that you feel comfortable submitting it to a press outlet. This last 7% will be for those who actually submit their project to one or more press outlets. The outlet doesn't have to cover your project, you just need to have sent it in.


## Schedule
* April 16th (Mon): Ideas & concepts presented
* April 23rd (Mon): Mid-project: considerable work needs to be done at this point.
* May 2nd (Wed): ***FINAL PROJECT PRESENTATIONS***
* May 7th (Mon): IM Show

## Repo
* Project Proposal
Project Theme: Demoji Danmaku
Background: A mainstream cultural phenomenon in some Japanese and Chinese Video website is users enjoy using Danmaku (Bullet Curtain) 
commenting function to send real-time or content-relavant comments that will show above video. In English enviroment, called Twitch Danmaku also applied the similar technology enabling viewers can comment on game livestreams. Althogh Danmaku is a great vibe creater and attracts viewers to get involved in the video, long Danmakus usually block the important content of videos and influence the watching experience. In this senario, the vibe of video can be amplified by the Danmaku but long Danmaku is neither readable or asthetic. Therefore, I am considering if there can be interesting function for video websites like Youtube to use AI to automaticly generate emojis or emoticons based on the sentence's content. Currently, there is a pre-trained API called Deepmoji, which can generate emoji by analazing the implying mood of the sentence, and I will use Youtube's API to use the Deepmoji to analyze Youtube's videos and generate corresponding emoji as transcript to show the vibe created implied the sentence. As a improvement, I will also try to analyze the comments of the video and generate the emoji based on them.    
Link to Deepmoji:(https://deepmoji.mit.edu/)    
Link to Youtube API:(https://developers.google.com/youtube/v3/code_samples/)    
Twitch Danmaku:
![sf](http://430.io/twitch-danmaku-chrome-extension-v1-1-1/)


